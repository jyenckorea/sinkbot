# trainer.py (NameError ìˆ˜ì • ë²„ì „)
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
import joblib
import os
import psycopg2
import sqlite3

# --- 1. ì‹¤í–‰ í™˜ê²½ ê°ì§€ ë° DB/ëª¨ë¸ ê²½ë¡œ ì„¤ì • ---
IS_CLOUD_ENV = 'DB_HOST' in os.environ

print("ğŸ¤– AI ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

if IS_CLOUD_ENV:
    # Cloudtype í™˜ê²½ (PostgreSQL)
    print("Cloud PostgreSQL ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    dsn = f"host={os.environ.get('DB_HOST')} port={os.environ.get('DB_PORT')} dbname={os.environ.get('DB_NAME')} user={os.environ.get('DB_USER')} password={os.environ.get('DB_PASSWORD')}"
    MODEL_DIR = "/data" # Cloudtypeì˜ ì˜êµ¬ ë””ìŠ¤í¬ ê²½ë¡œ
else:
    # ë¡œì»¬ ê°œë°œ í™˜ê²½ (SQLite)
    print("Local SQLite ëª¨ë“œ ('sinkbot_data.db')ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    DB_FILE = "sinkbot_data.db"
    MODEL_DIR = "." # í˜„ì¬ í´ë”

# --- 2. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ---
def load_data():
    """í™˜ê²½ì— ë”°ë¼ ì ì ˆí•œ DBì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    try:
        if IS_CLOUD_ENV:
            conn = psycopg2.connect(dsn)
        else:
            if not os.path.exists(DB_FILE):
                print(f"âŒ ë¡œì»¬ DB íŒŒì¼ '{DB_FILE}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. collector.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
                return None
            conn = sqlite3.connect(DB_FILE)
        
        df = pd.read_sql_query("SELECT * FROM displacement ORDER BY timestamp", conn)
        conn.close()
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {len(df)}ê°œì˜ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        return df
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ ---
def process_data(df):
    """AI í•™ìŠµì— ì‚¬ìš©í•  íŠ¹ì§•(feature)ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    df_copy = df.copy()
    df_copy['timestamp'] = pd.to_datetime(df_copy['timestamp'])
    df_copy = df_copy.sort_values(by='timestamp').reset_index(drop=True)
    reference_point = df_copy.iloc[0]
    
    # ê¸°ì¤€ì  ëŒ€ë¹„ ë³€ìœ„ ë° ë³€í™”ëŸ‰ ê³„ì‚°
    df_copy['delta_z'] = df_copy['z'] - reference_point['z']
    df_copy['distance_3d'] = np.sqrt((df_copy['x'] - reference_point['x'])**2 + (df_copy['y'] - reference_point['y'])**2 + (df_copy['z'] - reference_point['z'])**2)
    df_copy['tilt_magnitude'] = np.sqrt(df_copy['tilt_x']**2 + df_copy['tilt_y']**2)
    df_copy['delta_tilt'] = df_copy['tilt_magnitude'] - df_copy.iloc[0]['tilt_magnitude']
    
    return df_copy

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
df = load_data()

# ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆê³ , 20ê°œ ì´ìƒì¸ì§€ í™•ì¸
if df is not None and len(df) >= 20:
    print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    df_processed = process_data(df)

    # 4. AI ëª¨ë¸ í•™ìŠµ
    features = df_processed[['delta_z', 'distance_3d', 'delta_tilt']]
    
    contamination_level = 0.01 
    print(f"ëª¨ë¸ ë¯¼ê°ë„(Contamination)ë¥¼ {contamination_level * 100}%ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
    
    model = IsolationForest(contamination=contamination_level, random_state=42)

    print("â³ AI ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model.fit(features)
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

    # â­ï¸ 5. ëª¨ë¸ ì €ì¥ (í•™ìŠµì´ ì„±ê³µí–ˆì„ ë•Œë§Œ ì‹¤í–‰ë˜ë„ë¡ if ë¸”ë¡ ì•ˆìœ¼ë¡œ ì´ë™) â­ï¸
    try:
        if not os.path.exists(MODEL_DIR) and IS_CLOUD_ENV:
            os.makedirs(MODEL_DIR)
        
        model_filename = os.path.join(MODEL_DIR, "sinkbot_model.pkl")
        joblib.dump(model, model_filename)
        print(f"ğŸ’¾ í•™ìŠµëœ ëª¨ë¸ì„ '{model_filename}' íŒŒì¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ‰ ëª¨ë“  ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

else:
    if df is not None:
        print(f"âŒ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 20ê°œ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(df)}ê°œ)")
    # dfê°€ Noneì¸ ê²½ìš°ëŠ” load_data í•¨ìˆ˜ì—ì„œ ì´ë¯¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•¨

