# trainer.py (AI ëª¨ë¸ì„ DBì— ì €ì¥í•˜ë„ë¡ ìˆ˜ì •)
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
import joblib
import os
import psycopg2
import io

# --- 1. ì‹¤í–‰ í™˜ê²½ ê°ì§€ ë° DB ì—°ê²° ---
IS_CLOUD_ENV = 'DB_HOST' in os.environ

print("ğŸ¤– AI ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

conn = None
if IS_CLOUD_ENV:
    print("Cloud PostgreSQL ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    try:
        dsn = f"host={os.environ.get('DB_HOST')} port={os.environ.get('DB_PORT')} dbname={os.environ.get('DB_NAME')} user={os.environ.get('DB_USER')} password={os.environ.get('DB_PASSWORD')}"
        conn = psycopg2.connect(dsn)
        print("âœ… Cloud PostgreSQLì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ Cloud PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        exit(1)
else:
    print("âŒ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Cloudtype ë°°í¬ ì „ìš©ì…ë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” SQLite ë²„ì „ì˜ trainerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    exit(1)

# --- 2. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ---
def load_data():
    try:
        df = pd.read_sql_query("SELECT * FROM displacement ORDER BY timestamp", conn)
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {len(df)}ê°œì˜ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        return df
    except Exception as e:
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ ---
def process_data(df):
    df_copy = df.copy()
    df_copy['timestamp'] = pd.to_datetime(df_copy['timestamp'])
    df_copy = df_copy.sort_values(by='timestamp').reset_index(drop=True)
    reference_point = df_copy.iloc[0]
    
    df_copy['delta_z'] = df_copy['z'] - reference_point['z']
    df_copy['distance_3d'] = np.sqrt((df_copy['x'] - reference_point['x'])**2 + (df_copy['y'] - reference_point['y'])**2 + (df_copy['z'] - reference_point['z'])**2)
    df_copy['tilt_magnitude'] = np.sqrt(df_copy['tilt_x']**2 + df_copy['tilt_y']**2)
    df_copy['delta_tilt'] = df_copy['tilt_magnitude'] - df_copy.iloc[0]['tilt_magnitude']
    
    return df_copy

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
df = load_data()

if df is not None and len(df) >= 20:
    print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì§• ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    df_processed = process_data(df)

    # 4. AI ëª¨ë¸ í•™ìŠµ
    features = df_processed[['delta_z', 'distance_3d', 'delta_tilt']]
    contamination_level = 0.01 
    print(f"ëª¨ë¸ ë¯¼ê°ë„(Contamination)ë¥¼ {contamination_level * 100}%ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
    model = IsolationForest(contamination=contamination_level, random_state=42)
    print("â³ AI ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model.fit(features)
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

    # â­ï¸ 5. í•™ìŠµëœ ëª¨ë¸ì„ íŒŒì¼ì´ ì•„ë‹Œ DBì— ì €ì¥ â­ï¸
    try:
        # joblibì„ ì´ìš©í•´ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ ìƒì˜ ë°”ì´íŠ¸ ë°ì´í„°ë¡œ ë³€í™˜
        buffer = io.BytesIO()
        joblib.dump(model, buffer)
        buffer.seek(0)
        model_bytes = buffer.read()
        
        # ai_models í…Œì´ë¸”ì— ëª¨ë¸ ì €ì¥ (UPSERT: ì—†ìœ¼ë©´ INSERT, ìˆìœ¼ë©´ UPDATE)
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO ai_models (model_name, model_data)
                VALUES (%s, %s)
                ON CONFLICT (model_name) DO UPDATE
                SET model_data = EXCLUDED.model_data,
                    created_at = NOW();
                """,
                ('sinkbot_model', model_bytes) # ëª¨ë¸ ì´ë¦„ì€ 'sinkbot_model'ë¡œ ê³ ì •
            )
        conn.commit()
        print(f"ğŸ’¾ í•™ìŠµëœ ëª¨ë¸ì„ ë°ì´í„°ë² ì´ìŠ¤ 'ai_models' í…Œì´ë¸”ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥(ì—…ë°ì´íŠ¸)í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ‰ ëª¨ë“  ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        conn.rollback()
        print(f"âŒ ëª¨ë¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")

else:
    if df is not None:
        print(f"âŒ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 20ê°œ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(df)}ê°œ)")

if conn:
    conn.close()

